{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#モデル評価基準\" data-toc-modified-id=\"モデル評価基準-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>モデル評価基準</a></div><div class=\"lev2 toc-item\"><a href=\"#この章の目的\" data-toc-modified-id=\"この章の目的-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>この章の目的</a></div><div class=\"lev2 toc-item\"><a href=\"#予測誤差に基づく評価基準\" data-toc-modified-id=\"予測誤差に基づく評価基準-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>予測誤差に基づく評価基準</a></div><div class=\"lev3 toc-item\"><a href=\"#この節の目的\" data-toc-modified-id=\"この節の目的-121\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>この節の目的</a></div><div class=\"lev3 toc-item\"><a href=\"#予測二乗誤差\" data-toc-modified-id=\"予測二乗誤差-122\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>予測二乗誤差</a></div><div class=\"lev3 toc-item\"><a href=\"#クロス・バリデーション\" data-toc-modified-id=\"クロス・バリデーション-123\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>クロス・バリデーション</a></div><div class=\"lev4 toc-item\"><a href=\"#k分割クロス・バイデーション\" data-toc-modified-id=\"k分割クロス・バイデーション-1231\"><span class=\"toc-item-num\">1.2.3.1&nbsp;&nbsp;</span>k分割クロス・バイデーション</a></div><div class=\"lev4 toc-item\"><a href=\"#一般化クロス・バリデーション\" data-toc-modified-id=\"一般化クロス・バリデーション-1232\"><span class=\"toc-item-num\">1.2.3.2&nbsp;&nbsp;</span>一般化クロス・バリデーション</a></div><div class=\"lev3 toc-item\"><a href=\"#$C_p$-基準\" data-toc-modified-id=\"$C_p$-基準-124\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span><span class=\"MathJax_Preview\" style=\"color: inherit;\"><span class=\"MJXp-math\" id=\"MJXp-Span-341\"><span class=\"MJXp-msubsup\" id=\"MJXp-Span-342\"><span class=\"MJXp-mi MJXp-italic\" id=\"MJXp-Span-343\" style=\"margin-right: 0.05em;\">C</span><span class=\"MJXp-mi MJXp-italic MJXp-script\" id=\"MJXp-Span-344\" style=\"vertical-align: -0.4em;\">p</span></span></span></span><script type=\"math/tex\" id=\"MathJax-Element-18\">C_p</script> 基準</a></div><div class=\"lev3 toc-item\"><a href=\"#FPE\" data-toc-modified-id=\"FPE-125\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>FPE</a></div><div class=\"lev2 toc-item\"><a href=\"#情報量基準\" data-toc-modified-id=\"情報量基準-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>情報量基準</a></div><div class=\"lev3 toc-item\"><a href=\"#この節の目的\" data-toc-modified-id=\"この節の目的-131\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>この節の目的</a></div><div class=\"lev3 toc-item\"><a href=\"#カルバック・ライブラー情報量\" data-toc-modified-id=\"カルバック・ライブラー情報量-132\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>カルバック・ライブラー情報量</a></div><div class=\"lev3 toc-item\"><a href=\"#情報量基準AIC\" data-toc-modified-id=\"情報量基準AIC-133\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>情報量基準AIC</a></div><div class=\"lev4 toc-item\"><a href=\"#AIC\" data-toc-modified-id=\"AIC-1331\"><span class=\"toc-item-num\">1.3.3.1&nbsp;&nbsp;</span>AIC</a></div><div class=\"lev4 toc-item\"><a href=\"#モデルの最大対数尤度と自由パラメータ数\" data-toc-modified-id=\"モデルの最大対数尤度と自由パラメータ数-1332\"><span class=\"toc-item-num\">1.3.3.2&nbsp;&nbsp;</span>モデルの最大対数尤度と自由パラメータ数</a></div><div class=\"lev4 toc-item\"><a href=\"#ガウス型線形回帰モデルの有限修正\" data-toc-modified-id=\"ガウス型線形回帰モデルの有限修正-1333\"><span class=\"toc-item-num\">1.3.3.3&nbsp;&nbsp;</span>ガウス型線形回帰モデルの有限修正</a></div><div class=\"lev3 toc-item\"><a href=\"#マルチモデル推測\" data-toc-modified-id=\"マルチモデル推測-134\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>マルチモデル推測</a></div><div class=\"lev4 toc-item\"><a href=\"#モデル平均化法\" data-toc-modified-id=\"モデル平均化法-1341\"><span class=\"toc-item-num\">1.3.4.1&nbsp;&nbsp;</span>モデル平均化法</a></div><div class=\"lev2 toc-item\"><a href=\"#ベイズ型モデル評価基準\" data-toc-modified-id=\"ベイズ型モデル評価基準-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>ベイズ型モデル評価基準</a></div><div class=\"lev3 toc-item\"><a href=\"#この節の目的\" data-toc-modified-id=\"この節の目的-141\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>この節の目的</a></div><div class=\"lev3 toc-item\"><a href=\"#モデルの事後確率とBICの導出\" data-toc-modified-id=\"モデルの事後確率とBICの導出-142\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>モデルの事後確率とBICの導出</a></div><div class=\"lev4 toc-item\"><a href=\"#BIC\" data-toc-modified-id=\"BIC-1421\"><span class=\"toc-item-num\">1.4.2.1&nbsp;&nbsp;</span>BIC</a></div><div class=\"lev3 toc-item\"><a href=\"#ベイズ推測とモデル平均化法\" data-toc-modified-id=\"ベイズ推測とモデル平均化法-143\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>ベイズ推測とモデル平均化法</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル評価基準\n",
    "\n",
    "## この章の目的\n",
    "\n",
    "回帰モデリングでは想定したモデルの評価と選択という過程が必ずある。これまでにそれぞれ異なる基準に基づいて提唱されたいくつかの汎用的なモデル評価基準を取り上げ、それらをまとめる。\n",
    "\n",
    "## 予測誤差に基づく評価基準\n",
    "\n",
    "### この節の目的\n",
    "\n",
    "現象の真の構造と推定したモデルの違いを予測の観点からとらえた誤差、すなわち予測誤差の推定量として導かれた評価基準について述べる。その中で予測の観点からとらえた誤差である予測２乗誤差を定義し、その推定料として導かれた評価基準について述べる。\n",
    "\n",
    "### 予測二乗誤差\n",
    "\n",
    "以下の回帰モデルを考える。\n",
    "\n",
    "$$\n",
    "    y_i = u(x_i; \\beta) + \\epsilon_i, i = 1,2,\\cdots,n\\\\\n",
    "    (ここで、x = (x_1,x_2,\\cdots,x_p)^T)\n",
    "$$\n",
    "\n",
    "ここでモデルの適合度を評価する尺度として考えられるものとして残渣平方和(RSS)がある。\n",
    "\n",
    "$$\n",
    "    RSS = \\sum_{i = 1}^{n} \\{y_i - u(x_i;\\hat\\beta)\\}^2\n",
    "$$\n",
    "\n",
    "しかし、教科書の図５.1を見てもわかるように、単に次数をあげれば観測データへの当てはまりはよくなる。これは変数選択や次数選択の基準として有効に機能しないことでもある。(単に次数を上げれば最高！になってしまっている。)\n",
    "\n",
    "ここからわかることは、予測の観点が必要であるということである。モデルの良さはモデルを構築するときとは違うデータを用いることが必要。観測データとは独立にテストデータ$z_i$を用意することで、以下のPSS(predicted residual error sum of squares,PRESSとも呼ばれる.確認要)を考えることができる。\n",
    "\n",
    "$$\n",
    "    PSS = \\sum_{i = 1}^{n} \\{z_i - u(x_i;\\hat\\beta)\\}^2\n",
    "$$\n",
    "\n",
    "ここで、同じ大きさのデータが繰り返し採られた時の誤差は、以下のように定義できる。\n",
    "\n",
    "$$\n",
    "    PSE = \\sum_{i = 1}^{n} E[ \\{Z_i - u(x_i;\\hat\\beta)\\}^2 ]\n",
    "$$\n",
    "\n",
    "これはつまり、観測データとは独立に各点$x_i$でランダムに採られたデータ$Z_i = z_i$に対して平均的にどの程度違いがあるかを評価する。このPSEは予測二乗誤差と呼ばれる。\n",
    "\n",
    "しかし以上のように観測データとは別の独立した将来のデータを手に入れるということを前提に入れるのは現実的ではない。(過去の保存されたデータのみ残った場合とか？もう新しいデータが得られない場合など)観測データだけで予測の観点からモデルを評価する方式として以下のクロス・バリデーションがある。\n",
    "\n",
    "### クロス・バリデーション\n",
    "\n",
    "クロス・バリデーションはモデル推定に用いるデータとモデルの評価に用いるデータを分離して行う方式である。以下のステップを繰り返す。\n",
    "\n",
    "1. nこのデータの中からi番目のデータを登いてモデルを推定\n",
    "2. そのモデルにi番目のデータを入れることで、誤差を計算\n",
    "3. これをすべてのデータ点に対して繰り返して平均を取る値で評価をする\n",
    "\n",
    "$$\n",
    "    CV = \\frac{1}{n}\\sum_{i=1}^{n}\\{y_i - u(x_i;\\hat\\beta^{-i})\\}\n",
    "$$\n",
    "\n",
    "このCV値が最小となるモデルを選択する。\n",
    "ここで、クロス・バリデーションが予測二乗誤差の推定値であることは理論的に導かれる。\n",
    "ここに関しては以下の参考文献を参考にすること。\n",
    "* 小西・北川 2004 pp174-177\n",
    "* <a href=\"https://www.otexts.org/1490\">関連記事</a>\n",
    "\n",
    "#### k分割クロス・バイデーション\n",
    "\n",
    "ここで、データを一個づつの単位で取ることでなく、k個のセットで分けてから１個のセットづつをテストデータとして用いる方法\n",
    "\n",
    "#### 一般化クロス・バリデーション\n",
    "\n",
    "予測値ベクトル$\\hat y$と観測値ベクトル$y$の間に$y$に独立した行列$H(ハット行列)$を用いて、$\\hat y = H y $で表現できるモデルの場合には１個づつデータを取ってCVを計算することは不要であり、以下の式で計算できる。\n",
    "\n",
    "$$\n",
    "    CV = \\sum_{i=1}^{n} \\{ \\frac{y_i - u(x_i;\\hat\\beta)}{1 - h_{ii}} \\}^2\n",
    "$$\n",
    "\n",
    "ここで、分母に含まれる$1- h_{ii}$をその平均値$1 - n^{-1} tr H$で置き換えたのが次の一般化クロス・バリデーションである。\n",
    "\n",
    "$$\n",
    "    GCV = \\sum_{i=1}^{n} \\{ \\frac{y_i - u(x_i;\\hat\\beta)}{1 - n^{-1} tr H} \\}^2\n",
    "$$\n",
    "\n",
    "これを用いると効率的な計算が可能となる。このようなことがなぜ可能となるかは以下の参考文献を参考にすること。\n",
    "\n",
    "* 小西・北川 2004 pp178\n",
    "* Konishi and Kitagawa 2008 p243\n",
    "* <a href=\"https://www.otexts.org/1580\">関連記事1</a>\n",
    "* <a href=\"https://robjhyndman.com/hyndsight/loocv-linear-models/\">関連記事2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### $C_p$ 基準\n",
    "\n",
    "予測誤差に基づくモデル評価基準のうち、特に回帰モデルの変数選択に用いられるモデル選択基準にマローズの$C_p$基準がある。\n",
    "このモデル選択基準は線形回帰モデルの枠組みでデータを生み出す真の確率構造と想定した確率構造は異なるという仮定の素で、次のようにして導かれた。\n",
    "\n",
    "目的変数$y$に関するn個のデータからなる観測値ベクトル$\\textbf y$の期待値の期待値と共分散行列はそれぞれ以下のようであるとする。\n",
    "$$\n",
    "\\begin{align}\n",
    "    E[y] &= \\mu\\\\\n",
    "    cov(y) &= \\omega^2 I_n\n",
    "\\end{align}\n",
    "$$\n",
    "ここで真の期待値$\\mu$を以下のような線形回帰モデルを持って推定するとしよう。\n",
    "$$\n",
    "\\begin{align}\n",
    "    y &= X \\beta + \\epsilon\\\\\n",
    "    E[\\epsilon] &= 0\\\\\n",
    "    V(\\epsilon) &= \\sigma^2 I_n\n",
    "\\end{align}   \n",
    "$$\n",
    "こうするとこの線形回帰モデルの元で観測値のベクトル$\\textbf y$の期待値と分散共分散行列は以下のようになる。\n",
    "$$\n",
    "\\begin{align}\n",
    "    E[y] &= X\\beta\\\\\n",
    "    cov(y) &= \\sigma^2 I_n\n",
    "\\end{align}\n",
    "$$\n",
    "つまり、データの分散と線形回帰モデルの分散は異なるとして想定したモデルを用いて平均構造$\\mu$の推定をしようとしていることである。\n",
    "ここで線形回帰モデルの最小二乗法による推定量を$\\hat h$とおく。この推定量の良さをいあkの平均二乗誤差で測ることを考える。\n",
    "$$\n",
    "    \\Delta_p = E[(\\hat \\mu - \\mu)^T(\\hat \\mu - \\mu)]\n",
    "$$\n",
    "ここで、マローズの$C_p$基準はこの$\\Delta_p$の推定量に対して以下の式を用いる。\n",
    "$$\n",
    "    C_p = \\frac{(y - \\hat y)^T(y - \\hat y)}{\\hat\\omega^2} + \\{2(p + 1) - n\\}\n",
    "$$\n",
    "この$C_p$の値が小さいほど好ましいモデルであると考えるのがマローズの$C_p$ 基準である。\n",
    "詳細は以下の参考文献を参考にすること。\n",
    "* 小西・北川 2004 pp183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPE\n",
    "\n",
    "また、時系列の事故回帰モデルの次数選択を目的として予測二乗誤差の推定量として与えられたのが最終予測誤差FPE(Final Prediction Error; Akaike 1969)である。これは、例えば、最小二乗法で推定した線形回帰モデルに対しては以下の式で与えられる。\n",
    "$$\n",
    "    FPE = \\frac{n+p+1}{n(n-p-1)} (y - \\hat y)^T (y - \\hat y)\n",
    "$$\n",
    "これを変形すると以下のようになる。\n",
    "$$\n",
    "    FPE \\approx 2(p+1) + n \\log \\frac{1}{n} (y - \\hat y)^T (y - \\hat y)\n",
    "$$\n",
    "\n",
    "以上で見たマローズの$C_p$基準も、FPE基準もモデルの複雑さとともに減少する残差平方和に対して、複雑さのペナスティとしてモデルのパラメータ数$(p+1)$を評価基準に組み込んでいることがわかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情報量基準\n",
    "\n",
    "### この節の目的\n",
    "\n",
    "上の節で定義した予測二乗誤差とは観測データに基づいて推定したモデルを用いて各点での値を予測した時将来のデータと平均的にどの程度離れているかを点と点の距離で測ったものと言える。そして前節で述べた基準はこの距離の推定量となっていた。\n",
    "これに対して、構築したモデルを確率分布で表現して、データを発生した真の確率分布との距離をカルバック・ライブラー情報量で測るのが情報量基準の構成の基本的な考え方である。本節では回帰モデルに限らずに確率分布で表現された様々な統計モデルの評価を念頭に置いて、情報量基準の基本概念について述べる。\n",
    "そしてモデル選択基準として情報量基準AICに関して述べるAICは第２章から第４章までにも線形・非線形回帰モデルの評価と選択に用いてきたが、回帰モデルに限らず様々な問題への適応を念頭に、一般的な枠組みにおいてモデルの評価に対する考え方を踏まえて紹介する。\n",
    "\n",
    "### カルバック・ライブラー情報量\n",
    "\n",
    "最尤法でも止めた確率分布モデルがデータを発生する真の確率分布にどれだけ近いかを測ることを考える。\n",
    "このため、データyは密度関数gあるいは確率分布関数Gに従って生成されたとする。\n",
    "そして想定したモデルを$\\mathcal F = \\{ f(y|\\theta); \\theta \\in \\Theta \\in \\mathcal R^p\\}$とする。\n",
    "次に確率分布萌えるのパラメータ$\\theta$を最尤法で推定しそれを$\\hat \\theta$とする。将来のデータとの区分を明確にするために$\\hat \\theta(y)$と表すこともある。\n",
    "想定した確率モデルのパラメータを$\\hat \\theta$とした、モデル、つまり、$f(y|\\hat\\theta)$を統計モデルという。\n",
    "\n",
    "モデルを予測の観点から評価するために、将来真のモデルからランダムに採られたデータ$Z = z$の従う分布$g(z)$を構築した統計モデル$f(z|\\hat\\theta)$で予測した時の平均的な良さあるいは悪さを測る。\n",
    "\n",
    "ここで以下のカルバック・ライブラー情報量(K-L情報量)を用いる。\n",
    "$$\n",
    "    I\\{g(z);f(z|\\hat\\theta)\\} = E_G [\\log \\frac{g(Z)}{f(Z|\\hat\\theta)}]\n",
    "$$\n",
    "ここで、期待値は$\\hat \\theta = \\hat \\theta(y)$を固定して、将来のデータ$Z = z$の従う未知の確率分布に関してとる。\n",
    "K-L情報量に関しては以下の性質がある。\n",
    "\n",
    "1. $I\\{g(z);f(z|\\hat\\theta)\\} \\geq 0$\n",
    "2. $I\\{g(z);f(z|\\hat\\theta)\\} = 0 \\Leftrightarrow g(z) = f(z|\\hat\\theta)$\n",
    "\n",
    "K-L情報量が小さいほど統計モデルは真の確率分布に近いと考えることができる。\n",
    "このK-L情報量の値が小さいモデルを採用する方法でモデル選択を行う。\n",
    "\n",
    "ここで式変形を行うと以下のことがわかる。\n",
    "$$\n",
    "    I\\{g(z);f(z|\\hat\\theta)\\} = E_G [\\log g(Z)] - E_G [\\log f(Z|\\hat\\theta)]\n",
    "$$\n",
    "\n",
    "ここで後ろの$E_G [\\log f(Z|\\hat\\theta)]\u001c",
    "( = \\int \\log f(z|\\hat\\theta)g(z)dz )$(平均対数尤度)の値が大きいなモデルほど真のモデルに近いと言える。しかしこの値は未知の確率分布$g(z)$に依存するので計算はできない。\n",
    "よって、情報量基準の構成はこの平均対数尤度の有効な推定量を求めることに帰着される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 情報量基準AIC\n",
    "\n",
    "平均対数尤度式はデータを発生した未知の確率分布に依存しているが、この未知の確率分布を推定する方法の一つとしては、観測したデータから推定する方法が考えられる。\n",
    "\n",
    "すなわち、未知の確率分布$g(z)$を経験分布と呼ばれる離散型の確率分布\n",
    "$$\n",
    "    \\hat g(z) = \\frac{1}{n}, \\:\\: z = y_1, \\cdots, y_n\n",
    "$$\n",
    "で推定する方法がある。\n",
    "\n",
    "この結果、平均対数尤度の推定量として\n",
    "$$\n",
    "    E_G [\\log f(Z|\\hat\\theta)] = \\frac{1}{n} \\sum_{i=1}{n} \\log f(y_i | \\hat\\theta(y))\n",
    "$$\n",
    "を得る。これは、統計モデル$f(z|\\hat\\theta(y))$の対数尤度、あるいは対数尤度関数に最尤推定値を代入した最大対数尤度\n",
    "$$\n",
    "    \\mathcal l(\\hat\\theta) = \\sum_{i=1}^{n} \\log(y_i|\\hat\\theta(y)) = \\log f(y|\\hat\\theta(y))\n",
    "$$\n",
    "の$n^{-1}$倍の関係である。\n",
    "\n",
    "ここでこの対数尤度は平均対数尤度の推定量ではあるが、将来のデータに変えてモデル推定に用いたデータ$\\textbf y$を再び利用して平均対数尤度を推定したことから、推定のバイアス$\\log f(y|\\hat\\theta(y)) - n E_G [\\log f(Z|\\hat\\theta)]$を生じる原因となっている。ここで同じ大きさのデータが繰り返し抽出さえる時の期待されるバイアスは以下の式となる。\n",
    "\n",
    "$$\n",
    "    bias(G) = E_G[ \\log f(Y|\\hat\\theta(Y)) - n E_G [\\log f(Z|\\hat\\theta(Y))] ]\n",
    "$$\n",
    "\n",
    "ここで期待値は$Y$の同時分布に関してとる。従って、このバイアスを何らかの方式で評価して、対数尤度のバイアスを補正した、\n",
    "$$\n",
    "\\begin{align}\n",
    "    IC &= -2(統計モデルの対数尤度) + 2(バイアス補正項)\\\\\n",
    "       &= -2 \\log f(y|\\hat\\theta) + 2 (バイアス補正項)\n",
    "\\end{align}\n",
    "$$\n",
    "を情報量基準という。\n",
    "\n",
    "#### AIC\n",
    "\n",
    "ここでAICは以下の式で構成される情報量基準である。\n",
    "$$\n",
    "\\begin{align}\n",
    "    AIC &= -2(モデルの最大対数尤度) + 2(モデルの自由パラメータ数)\\\\\n",
    "       &= -2 \\log f(y|\\hat\\theta) + 2 (モデルの自由パラメータ数)\n",
    "\\end{align}\n",
    "$$\n",
    "このAICを最小にするモデルを最適なモデルとして選択する方法をAIC最小化法という。\n",
    "\n",
    "#### モデルの最大対数尤度と自由パラメータ数\n",
    "\n",
    "モデルの最大対数尤度の部分はモデルのデータへの適合度を表し、モデルが複雑になるにつれてこの値は小さくなる。AICはモデルの複雑さとともに現状するこの値に対して、逆に増加するモデルのパラメータ数をペナルティとして評価基準に組み込んでいることがわかる。\n",
    "\n",
    "多数のパラメータで特徴付けられた複雑なモデルの方が、観測したデータへのモデルの当てはまりは良い。しかし複雑すぎるモデルは将来の現象予測に有効に働かない。このため、観測されたデータの情報に基づいて予測の観点から最適なモデルを選択するには、モデルのデータへの適合度とモデルの複雑さを適切に調整する必要があることを示している。\n",
    "\n",
    "#### ガウス型線形回帰モデルの有限修正\n",
    "\n",
    "データを発生した真の確率分布は想定してモデルの中に含まれるとする。(パラメータを調整すると一致する分布が得られる。)この時対数尤度のバイアスは、正規分布の特性を用いて精確に求めることが可能であり、次式で与えられる。\n",
    "$$\n",
    "    E_G[ \\log f(Y|\\hat\\theta(Y)) - \\int \\log f(z|\\hat\\theta(Y)) g(z) dz ] = \\frac{n(p+2)}{n-p-3}\n",
    "$$\n",
    "ここで期待値は$Y$の同時分布に対してとる。\n",
    "\n",
    "これによって、対数尤度の精確なバイアスを補正した以下の情報量基準を得ることができる。\n",
    "$$\n",
    "    AIC_C = n \\{ \\log (2\\pi\\hat\\sigma^2) + 1 \\} + 2\\frac{n(p+2)}{n-p-3}\n",
    "$$\n",
    "\n",
    "ここで、この補正項を1/nオーダーで級数展開すると、\n",
    "$$\n",
    "    \\frac{n(p+2)}{n-p-3} \\approx p + 2\n",
    "$$\n",
    "かわかる。ここからも情報量基準AICはモデルの対数尤度の漸近バイアスを補正したものであることがわかる。\n",
    "\n",
    "ただ、このような精確なバイアス補正を一般的な枠組みで論議することは難しい。\n",
    "\n",
    "### マルチモデル推測\n",
    "\n",
    "モデル選択とは、データに基づいて構築された複数の候補モデルの中から、データ発生の確率構造を最もよく近似するモデルを1つ選択することである。\n",
    "これに対してマルチモデル推測とは、構築した複数のモデルの相対的な重要性あるいはモデルの確からしさを加重値として用いて、モデル集合に基づいて推論を実行する方法であると言える。\n",
    "\n",
    "#### モデル平均化法\n",
    "\n",
    "この方式は、例えば、良いモデルに大きく重みづけした上で複数のモデルの回帰係数の平均値を求め、一つのモデルを構成する方法と考えることができる。Akaikeは最小AIC値と各モデルのAIC値との差に基づくモデルの相対的な確からしさを尤度と関連づけた考え方を述べているが、これに関連して、Burnham and Andersonはこれをモデル平均化法における加重値として定式化した。\n",
    "\n",
    "この候補モデル集合に属する各モデルに、最小情報量基準値との差に基づくオーダーをつけ、相対的確からしさを重みとしてモデルを平均化する推測法は様々な問題への適用可能性を秘めているが、その理論研究は今後の課題として残されている。\n",
    "\n",
    "モデル平均化法はモデル選択の不確定性に対処するための1つのアプローチであると言える。同様に2つのモデルのAICの差の有意性の検定や信頼集合を構成して不確定性を献上する方法(Linhart(1988), Shimodaira(1997))、観測データからブートストラップ標本を反復抽出してモデル選択を繰り返し実行し、各モデルが選択される頻度を推定するブートストラップ選択確率に基づく方法などがある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベイズ型モデル評価基準\n",
    "\n",
    "### この節の目的\n",
    "\n",
    "この節ではAICと同様に最尤法によって推定されたモデルの評価基準として、ベイズ理論によるモデルの事後確率に基づいて構成されたベイズ型情報量基準BIC(Schwarz(1978))の導出の概略について述べる。さらに、モデルの相対的な重要性を考慮に入れて、複数のモデルから平均的なモデルを求めるなどといった方法によりモデル集合に基づく推測を行う、マルティモデル推測やモデル平均化法についてもふれる。\n",
    "\n",
    "### モデルの事後確率とBICの導出\n",
    "\n",
    "ベイズ理論による事後分布が最も高くなるようなモデルを最適なモデルとして選択するというのがBICの基本的な考え方である。以下のその導出を示す。\n",
    "\n",
    "BIC を導出するための出発点は，ベイズの定理である。いま、r個のモデル族を$M_1, \\cdots , M_r$とし、i番目のモデル族が生起する事前確率を$P(M_i)$とすると、i 番目のモデル族の事後確率は、ベイズの定理より、\n",
    "$$\n",
    "    P(M_i | y) = \\frac{p_i(y) P(M_i)}{\\sum_{j=1}^{r} p_j(y) P(M_j)}, \\:\\: (i = 1,\\cdots,r)\n",
    "$$\n",
    "で与えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、各モデル族$M_i$は確率密度関数$f_i(y|θ_i) \\:\\: (θ_i \\in Θ_i \\subset R^{p_i} )$とパラメータ$θ_i$の事前分布 $\\pi_i(θ_i)$によって特徴付けられているとする。このとき、データ$y = \\{ y_1, \\cdots, y_n \\}$に関するモデル族$M_i$の周辺尤度\n",
    "$$\n",
    "    p_i(y) = \\int f_i(y|\\theta_i)\\pi_i(\\theta_i)d\\theta_i\n",
    "$$\n",
    "はi番目のモデル族からデータが得られる確からしさと考えられる。\n",
    "\n",
    "ベイズ統計学の考え方に基づいて、事後確率が最大となるモデル族を採用することにする。いま、事前確率$P(M_i)$はすべて等しいと仮定すれば、データの周辺尤度$p_i(y)$を最大にするモデル族を選択することになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、データの周辺尤度は、ラプラス近似を用いて求めることができる。\n",
    "ここに関して以下の参考文献を参照すること。\n",
    "\n",
    "* 教科書p119,120,121\n",
    "* <a href=\"https://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/56989/1/yamaguchi.pdf\">参考文献</a>\n",
    "\n",
    "近似の結果は以下のようである。通常、自然対数を取って-2を乗じた次の形で用いられている。\n",
    "$$\n",
    "    -2\\log p_i (y) \\approx -2 \\log f_i (y|\\hat\\theta_i) + p_i \\log n\n",
    "$$\n",
    "ただし、$\\hat\\theta_i$はモデル$f_i (y|\\theta_i)$の$p_i$次元パラメータベクトル$\\theta_i$の最尤推定値である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上より、一般に、最尤法によって推定された統計モデル$f(y|\\hat\\theta)$を評価するためのベイズ型モデル評価基準BICは次の式で与えられ、BICの値を最小とするモデルを最適なモデルとして選択する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIC\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    BIC &= -2(モデルの最大対数尤度) + \\log n (モデルの自由パラメータ数)\\\\\n",
    "       &= -2 \\log f(y|\\hat\\theta) + \\log n (モデルの自由パラメータ数)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベイズ推測とモデル平均化法\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベイズ型モデル評価基準BICはモデリングの家庭のおいて将来の現象予測に用いる最適な近似モデルを選択するための基準であった。これに対して複数のモデルに基づく現象予測に視点を移したのが、マルティモデル推測である。ここでは、ベイズアプローチに基づくモデル平均化法による予測分布の構成法について述べる。\n",
    "\n",
    "上のBICの導出の時と同様に、r個のモデル族を$M_1, \\cdots , M_r$とし、各モデル族$M_i$は確率密度関数$f_i(y|θ_i) \\:\\: (θ_i \\in Θ_i \\subset R^{p_i} )$とパラメータ$θ_i$の事前分布 $\\pi_i(θ_i)$によって特徴付けられているとする。\n",
    "\n",
    "この時、予測分布モデルは、予測の視点あkら将来のデータ$Z = z$に関する推測を行うのに用いられ、次式で定義される。\n",
    "$$\n",
    "    h_i(z|y) = \\int f_i (z|\\theta_i) \\pi_i (\\theta_i | y) d \\theta_i , \\:\\: i = 1,\\cdots,r\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、ここで$\\pi_i (\\theta_i | y)$は以下の式で定義される事後分布である。\n",
    "$$\n",
    "    \\pi_i (\\theta_i | y) = \\frac{f_i (y|\\theta_i) \\pi_i (\\theta_i)}{\\int f_i (y|\\theta_i) \\pi_i (\\theta_i) d \\theta_i}\n",
    "$$\n",
    "このrこの予測分布モデルに何らかの重みをつけてモデルを構築するのがベイズアプローチによるモデル平均化法の基本的な考え方である。ここで、ベイズ理論におけるモデル平均化法の予測分布モデルは、重みに次で定義される事後確率を用いる。\n",
    "$$\n",
    "    P(M_i | y) = \\frac{p_i(y) P(M_i)}{\\sum_{j=1}^{r} p_j(y) P(M_j)}, \\:\\: (i = 1,\\cdots,r)\n",
    "$$\n",
    "ただし、$p_i(y)$は以下のようである。\n",
    "$$\n",
    "    p_i(y) = \\int f_i(y|\\theta_i)\\pi_i(\\theta_i)d\\theta_i\n",
    "$$\n",
    "\n",
    "その結果、ベイズ推論におけるモデル平均化法による予測分布モデルは以下の式となる。\n",
    "$$\n",
    "    h_i(z|y) = \\sum_{i=1}^{r} P(M_i|y)h_i(z|y)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このモデルはモデル集合に属する各モデルの相対的な確からしさを事後確率で評価して、それを重みとして用いた加重平均から構築されたこととなる。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "504px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "6",
   "toc_cell": true,
   "toc_position": {
    "height": "1762px",
    "left": "0px",
    "right": "988px",
    "top": "84px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
